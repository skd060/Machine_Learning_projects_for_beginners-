{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as ly\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,train_out), (test_images,test_out) = data.load_data()\n",
    "# print (train_images.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "(train_images,test_images) = train_images/255.0 , test_images/255.0\n",
    "train_images = train_images.reshape(train_images.shape[0],train_images.shape[1],train_images.shape[2],1)\n",
    "test_images = test_images.reshape(test_images.shape[0], test_images.shape[1],test_images.shape[2],1)\n",
    "train_out, test_out = to_categorical(train_out), to_categorical(test_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 32)        25632     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1568)              2460192   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                15690     \n",
      "=================================================================\n",
      "Total params: 2,502,346\n",
      "Trainable params: 2,502,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(ly.Conv2D(32,kernel_size=(5,5),strides=1,activation='relu',padding='same',input_shape=(28,28,1)))\n",
    "model.add(ly.Dropout(0.2))\n",
    "model.add(ly.MaxPool2D(pool_size=(2,2),strides=2,padding='same'))\n",
    "model.add(ly.Conv2D(32,kernel_size=(5,5),strides=1,padding='same',activation='relu'))\n",
    "model.add(ly.Dropout(0.2))\n",
    "model.add(ly.MaxPool2D(pool_size=(2,2),strides=2,padding='same'))\n",
    "model.add(ly.Flatten())\n",
    "model.add(ly.Dense(1568,activation='relu'))\n",
    "model.add(ly.Dense(10,activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 157s 3ms/step - loss: 0.1618 - acc: 0.9504 - val_loss: 0.0659 - val_acc: 0.9808\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 152s 3ms/step - loss: 0.0494 - acc: 0.9847 - val_loss: 0.0450 - val_acc: 0.9874\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 153s 3ms/step - loss: 0.0340 - acc: 0.9895 - val_loss: 0.0383 - val_acc: 0.9897\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 152s 3ms/step - loss: 0.0245 - acc: 0.9921 - val_loss: 0.0338 - val_acc: 0.9912\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 152s 3ms/step - loss: 0.0203 - acc: 0.9932 - val_loss: 0.0315 - val_acc: 0.9907\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 152s 3ms/step - loss: 0.0156 - acc: 0.9949 - val_loss: 0.0330 - val_acc: 0.9894\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 152s 3ms/step - loss: 0.0120 - acc: 0.9960 - val_loss: 0.0352 - val_acc: 0.9889\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 152s 3ms/step - loss: 0.0125 - acc: 0.9957 - val_loss: 0.0305 - val_acc: 0.9902\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 152s 3ms/step - loss: 0.0117 - acc: 0.9958 - val_loss: 0.0329 - val_acc: 0.9910\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 154s 3ms/step - loss: 0.0097 - acc: 0.9967 - val_loss: 0.0295 - val_acc: 0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x49b3c5f8>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images,train_out,validation_split=0.2,epochs=10,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 9s 924us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.025922910743330432, 0.9916]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images,test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnistCNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Image.open('test4.png').convert('L')\n",
    "img = img.resize((28,28))\n",
    "# img1= plt.imread('test2.jpg')\n",
    "plt.imshow(img1)\n",
    "im2arr = np.array(img)\n",
    "\n",
    "im2arr = im2arr/255.0\n",
    "plt.imshow(im2arr)\n",
    "im2arr = im2arr.reshape(1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1480301e-02, 1.1264405e-03, 1.6554138e-01, 7.8289711e-01,\n",
       "        2.4839707e-03, 4.1014533e-03, 2.4264875e-04, 2.5631995e-03,\n",
       "        1.1170991e-02, 1.8392669e-02]], dtype=float32)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(im2arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
